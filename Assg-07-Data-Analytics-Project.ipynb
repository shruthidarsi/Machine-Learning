{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "import urllib.request # request library for downloading a url\n",
    "import os.path\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Train-test data split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 8) # set default figure size, 8in by 6in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Download of UCI Data Set\n",
    "\n",
    "Here is an example of downloading a file from an internet URL address, then loading it into\n",
    "a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a report hook function, so that the urlretrieve() can display\n",
    "# a status report while downloading\n",
    "def urlretrieve_reporthook(block_number, read_size, total_file_size):\n",
    "    if block_number % 100 == 0:\n",
    "        print(\"\\rReading %d / %d complete\" % (read_size * block_number, total_file_size), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the UCI datasets have been pre-divided into test and training sets\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv'\n",
    "train_file = './data/risk_factors_cervical_cancer.csv'\n",
    "\n",
    "# download the training data csv (comma separated values) file into our data folder\n",
    "# I picked a relatively large dataset file/example here (45 MB), so this may take a bit of time to\n",
    "# download on a slow connection.\n",
    "# always good to check and only download if we don't already have the file, so we can more easily\n",
    "# rerun all cells without causing a long download to be done every time\n",
    "if not os.path.exists(train_file):\n",
    "    print('Beginning file download with urllib2...')\n",
    "    urllib.request.urlretrieve(url, train_file, reporthook=urlretrieve_reporthook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "# Problem space\n",
    "      Here I am using risk_factors_cervical_cancer data, and it has 36 columns and 858 rows. There are 32 input features and 4 output features available. We would want here to find out the relavant features and try to create model that fits well with data. I am going to try all the different models and compare the accuracy and then decide which one fits the data without noice or loss of data.\n",
    "      Using this cervical cancer dataset, I will first try to explore the data to identify the primary or required features, and then use them to create a model.\n",
    "  \n",
    "      At first, I will do these tasks.\n",
    "          > Data loading\n",
    "          > Data cleaning\n",
    "          > Data preprocessing\n",
    "          > Data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file into a pandas dataframe\n",
    "# the train file we receive has 20 lines of copyright/header information we need to skip over\n",
    "# also the csv file uses na to represent missing data, which is not interpreted as a missing by\n",
    "# pandas by default.  By specifying this as a na_values, all of the columnes are interpreted \n",
    "# as numberic types and NaN are the numeric values given to the missing data.\n",
    "\n",
    "cancerData = pd.read_csv(train_file)\n",
    "print(cancerData.info())\n",
    "#print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning\n",
    "    As first step, we are making data to make more sense so that the features can give valid accuracy and predict the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 (a) Finding missing values\n",
    "    In my dataset had '?' instead of missing values for some reason. I am trying here to replace them as NA(missing values)n and then trying to replace missing values. Replacing can be done in these ways. \n",
    "    1. Convert categorical to Numerical (cancerData doesn't have any categorical data, it's all numeric. So I can ignore this step)\n",
    "    2. Remove irrelavant columns (optional), \"STDs: Time since first diagnosis\" and \"STDs: Time since last diagnosis\" are mostly having missing values and it need not be relavant for my model. So , i removed(dropped) irrelavant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the columns below because these have almost 90% of missing data\n",
    "#isnull().sum() shows what all columns has NA values and how many rows NA data exists.\n",
    "cancerData.drop(columns=['STDs: Time since first diagnosis', 'STDs: Time since last diagnosis'], axis=1, inplace=True,errors='raise')\n",
    "cancerData.replace('?', np.nan, inplace=True)\n",
    "print(cancerData.isnull().sum())\n",
    "cancerData = cancerData.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 (b) Resolving Missing values\n",
    "       Replacing the missing values with 0's or mean() or median() whichever is suitable for the column. \n",
    "       1. \"Age\" column doesnt have any missing data.  \n",
    "       2. \"Number of sexual partners\" and \"First sexual intercourse\" NAs are replcaed with mean() values as they dont have outliers.\n",
    "       3. \"Number of pregnancies\" , \"IUD\" and \"IUD(years)\" are replaced with 0\n",
    "       4. remaining all other columns are replaced with median() values as they may have much outliers.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerData['Number of sexual partners'].fillna(cancerData[\"Number of sexual partners\"].mean(), inplace=True)\n",
    "cancerData['First sexual intercourse'].fillna(cancerData[\"First sexual intercourse\"].mean(), inplace=True)\n",
    "cancerData['Num of pregnancies'].fillna(0, inplace=True)\n",
    "\n",
    "cancerData['IUD'].fillna(0, inplace=True)\n",
    "cancerData['IUD (years)'].fillna(0, inplace=True)\n",
    "\n",
    "cancerData['Smokes'].fillna(cancerData[\"Smokes\"].median(), inplace=True)\n",
    "cancerData['Smokes (years)'].fillna(cancerData[\"Smokes (years)\"].median(), inplace=True)\n",
    "cancerData['Smokes (packs/year)'].fillna(cancerData[\"Smokes (packs/year)\"].median(), inplace=True)\n",
    "\n",
    "cancerData['Hormonal Contraceptives'].fillna(cancerData[\"Hormonal Contraceptives\"].median(), inplace=True)\n",
    "cancerData['Hormonal Contraceptives (years)'].fillna(cancerData[\"Hormonal Contraceptives (years)\"].median(), inplace=True)\n",
    "\n",
    "cancerData['STDs'].fillna(cancerData[\"STDs\"].median(), inplace=True)\n",
    "cancerData['STDs (number)'].fillna(cancerData[\"STDs (number)\"].median(), inplace=True)\n",
    "#cancerData['STDs:condylomatosis'].fillna(cancerData[\"STDs:condylomatosis\"].median(), inplace=True)\n",
    "#cancerData['STDs:cervical condylomatosis'].fillna(cancerData[\"STDs:cervical condylomatosis\"].median(), inplace=True)\n",
    "cancerData['STDs:vaginal condylomatosis'].fillna(cancerData[\"STDs:vaginal condylomatosis\"].median(), inplace=True)\n",
    "cancerData['STDs:vulvo-perineal condylomatosis'].fillna(cancerData[\"STDs:vulvo-perineal condylomatosis\"].median(), inplace=True)\n",
    "cancerData['STDs:syphilis'].fillna(cancerData[\"STDs:syphilis\"].median(), inplace=True)\n",
    "cancerData['STDs:pelvic inflammatory disease'].fillna(cancerData[\"STDs:pelvic inflammatory disease\"].median(), inplace=True)           \n",
    "cancerData['STDs:genital herpes'].fillna(cancerData[\"STDs:genital herpes\"].median(), inplace=True)\n",
    "cancerData['STDs:molluscum contagiosum'].fillna(cancerData[\"STDs:molluscum contagiosum\"].median(), inplace=True)\n",
    "cancerData['STDs:AIDS'].fillna(cancerData[\"STDs:AIDS\"].median(), inplace=True)\n",
    "cancerData['STDs:HIV'].fillna(cancerData[\"STDs:HIV\"].median(), inplace=True)\n",
    "cancerData['STDs:Hepatitis B'].fillna(cancerData[\"STDs:Hepatitis B\"].median(), inplace=True) \n",
    "cancerData['STDs:HPV'].fillna(cancerData[\"STDs:HPV\"].median(), inplace=True) \n",
    "cancerData['STDs:condylomatosis'].fillna(cancerData[\"STDs:HPV\"].median(), inplace=True) \n",
    "\n",
    "cancerData['STDs:cervical condylomatosis'].fillna(cancerData[\"STDs:HPV\"].median(), inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some information about the data\n",
    "num_samples, num_features = cancerData.shape\n",
    "print(\"Number of features:\", num_features)\n",
    "print(\"number of training samples:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the datatypes of each column\n",
    "print(cancerData.dtypes)\n",
    "\n",
    "# The count for describe shows the total present values for each feature out of the 60000 samples for each one.\n",
    "cancerData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first column is actually the label/target we would want to use if we were to build a classifier.\n",
    "#Biopsy has 0 or 1 values which we can classify as binary classification\n",
    "#We have 4 to 5 output variables that declares the cancer confirmation, but as of now i am using 'Biopsy' as output.\n",
    "np.unique(cancerData['Biopsy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would want to remove this column from the training data, and create a y (training labels), that uses 0 for\n",
    "#removed last feature, and added to y. Remaing columns are added to input features x\n",
    "x = cancerData.iloc[:,:-1]\n",
    "print(x.shape)\n",
    "y = cancerData.Biopsy.values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data\n",
    "Using histogram and boxplot on age just for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the joint plots using sns \n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.boxplot([cancerData.iloc[:,0], y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram for all the columns\n",
    "cancerData.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train data split\n",
    "1. Split the data to train and test set with 80-20 ratio\n",
    "2. plot the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=19)\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardization\n",
    "    Cancer dataset has more skewy data, so iam trying to standardise so that it's easier to estimate or compare.\n",
    "    I am trying to standardise the whole data to understand first, later I will be using the scalar function on train and test data seperately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Get column names first\n",
    "names = cancerData.columns\n",
    "# Create the Scaler object\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "# Fit data on the scaler object\n",
    "scaled_cancerData = std_scaler.fit_transform(cancerData)\n",
    "#scaled_cancerData = pd.DataFrame(scaled_df, columns=names)\n",
    "print(scaled_cancerData.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling data\n",
    "We can apply unsupervised learning algorithms to unserstand the sensitivity of the data. But here I am using normal regressions and classifiers and then comparing the score values of each.    \n",
    "I am applying regression and classificarion models to see which one is suitable for my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(x_train, y_train)\n",
    "\n",
    "print(model_1.intercept_)\n",
    "print(model_1.coef_)\n",
    "y_pred = model_1.predict(x_test)\n",
    "model_1.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_2 = LogisticRegression(solver='lbfgs', max_iter=600)\n",
    "model_2.fit(x_train, y_train)\n",
    "\n",
    "print(model_2.intercept_)\n",
    "print(model_2.coef_)\n",
    "y_pred = model_2.predict(x_test)\n",
    "print(y_pred)\n",
    "model_2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model - For classification (Linear kernel)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn import svm\n",
    "linclf = svm.SVC(kernel='linear', C=1e6)\n",
    "linclf.fit(x_train, y_train)\n",
    "print((linclf.coef_))  # show the coefficients that were fitted to the data by logistic regression\n",
    "print((linclf.intercept_))\n",
    "\n",
    "\n",
    "#Here , classification and Regression are having same r squared values.\n",
    "linclf.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly - kernel SVM\n",
    "#Lets try to improve by poly kernel and see what happens\n",
    "linclf2 = svm.SVC(kernel='poly', C=1e6)\n",
    "linclf2.fit(x_train, y_train)\n",
    "print((linclf2.intercept_))\n",
    "\n",
    "linclf2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "    risk_factors_cervical_cancer has 34 features with 858 samples. Output feature is \"Biopsy\" and there are many dependant variables for out feature. \n",
    "    R-square values of each model are:\n",
    "    Linear Regression = 20.27% \n",
    "    Logistic Regression = 94.18%\n",
    "    Linear SVM = 94.18%\n",
    "    Poly kernal SVM = 90.69%\n",
    "    \n",
    "    So, we can clearly say that the data is suitable for classification or Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
